{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating DG Data using Simbench and Powerdata-gen\n",
    "\n",
    "[1] https://github.com/e2nIEE/simbench  \n",
    "[2] https://github.com/bdonon/powerdata-gen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dependencies, including the data generator library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "DATA_GEN_PATH = os.path.abspath('powerdata-gen/')\n",
    "sys.path.append(DATA_GEN_PATH)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandapower as pp\n",
    "import simbench as sb\n",
    "import powerdata_gen\n",
    "from omegaconf import OmegaConf\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "import time\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions to load pandapower grids from simbench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_output_dir():\n",
    "    identifier = time.strftime('%Y-%m-%d_%H:%M:%S')\n",
    "    output_dir = os.path.join('outputs', identifier)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    return output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dist_grid_codes():\n",
    "    # Create the codes for the distribution grid cases of Simbench (LV and MV and any combination of the two)\n",
    "    codes = sb.collect_all_simbench_codes(scenario=0)\n",
    "    dist_grid_codes = list(filter(lambda x: \"-MV-\" in x or \"-LV-\" in x or \"-MVLV-\" in x, codes))\n",
    "    return sorted(dist_grid_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pandapower_grid_to_json(sb_code: str, filename: str):\n",
    "    net = sb.get_simbench_net(sb_code)\n",
    "    pp.to_json(net, filename)\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions for extracting node features and edge features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node_features(net):\n",
    "    # List of bus features\n",
    "    #   x: np.array([Slack?, PV?, PQ?, p_mw, q_mvar, vm_pu, va_degree])\n",
    "    #   y: np.array([p_mw, q_mvar, vm_pu, va_degree])\n",
    "    #\n",
    "    node_features_x, node_features_y = [], [] # map from bus_id to features\n",
    "    for bus_id in net.bus.index:\n",
    "        # (Slack?, PV?, PQ?)\n",
    "        bus_type = (0, 0, 1)\n",
    "\n",
    "        gens = net.gen.loc[net.gen['bus'] == bus_id]\n",
    "        if len(gens) > 0:\n",
    "            bus_type = (0, 1, 0)\n",
    "\n",
    "        slack = net.ext_grid.loc[net.ext_grid['bus'] == bus_id,\n",
    "                        ['vm_pu', 'va_degree']]\n",
    "        if len(slack) > 0:\n",
    "            assert len(gens) == 0, (\"PV and Swing generators cannot be placed\"\n",
    "                                    \" on the same bus. This is because they\"\n",
    "                                    \" will both try to control the bus voltage.\")\n",
    "            bus_type = (1, 0, 0)\n",
    "        \n",
    "        # net.res_bus should already take into account all the components that\n",
    "        # contribute to these four bus parameters so we do not have to do this\n",
    "        # again (ex. loads, sgens, gens, storages, ext_grid, etc.).\n",
    "        features = net.res_bus.loc[bus_id, ['p_mw', 'q_mvar', 'vm_pu', 'va_degree']]\n",
    "        masked_features = features.copy()\n",
    "        if bus_type[0]:\n",
    "            masked_features['p_mw'] = np.nan\n",
    "            masked_features['q_mvar'] = np.nan\n",
    "        elif bus_type[1]:\n",
    "            masked_features['q_mvar'] = np.nan\n",
    "            masked_features['va_degree'] = np.nan\n",
    "        else:\n",
    "            masked_features['vm_pu'] = np.nan\n",
    "            masked_features['va_degree'] = np.nan\n",
    "\n",
    "        node_features_x.append(np.append(bus_type, masked_features.values))\n",
    "        node_features_y.append(features.values)\n",
    "    \n",
    "    return np.array(node_features_x), np.array(node_features_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edge_features(net):\n",
    "    # List of edge features\n",
    "    #   e: np.array([trafo?, r_pu, x_pu, phase_shift])\n",
    "\n",
    "    def get_line_features(net):\n",
    "        # Undirected graph so need to add both directions to edge_index.\n",
    "        edge_index = net.line.loc[:, ['from_bus', 'to_bus',\n",
    "                                      'to_bus', 'from_bus']].values\n",
    "        # Use .reshape to change shape from (E, 4) to (2E, 2), where E is num edges.\n",
    "        # Transpose to make into proper (2, 2E format).\n",
    "        edge_index = edge_index.reshape(-1, 2).T\n",
    "\n",
    "        # TODO: Decide if use r/x or G/B??\n",
    "        r = net.line['r_ohm_per_km'].values * net.line['length_km'].values\n",
    "        x = net.line['x_ohm_per_km'].values * net.line['length_km'].values\n",
    "\n",
    "        # We convert the r,x values into per unit (p.u.) to simplify calculations\n",
    "        # and ensure consistency across the network. To do this, we divide r, x by\n",
    "        # the base impedance. Therefore z = vn_kv**2/sn_mva, where vn_kv is rated\n",
    "        # voltage and sn_mva is reference apparent power.\n",
    "        # Note: vn_kv be the same for every bus except ext_grid, but this is safer.\n",
    "        vn_kv = net.bus.loc[net.line['to_bus'], ['vn_kv']].values.reshape(-1)\n",
    "        z = np.square(vn_kv) / net.sn_mva\n",
    "        r_pu = r / z\n",
    "        x_pu = x / z\n",
    "\n",
    "        # Similarly, due to undirected graph, the edge features need to be repeated\n",
    "        # twice, once for each respective connection present in the COO matrix.\n",
    "        r_pu = r_pu.repeat(2)\n",
    "        x_pu = x_pu.repeat(2)\n",
    "\n",
    "        # Add zeros to indicate it is a line, and pad with nan to account for\n",
    "        # missing phase shift.\n",
    "        e = edge_index.shape[1] # b/c coo matrix\n",
    "        edge_features = np.vstack([np.zeros(e),         # trafo?\n",
    "                                   r_pu,                # r_pu\n",
    "                                   x_pu,                # x_pu\n",
    "                                   np.nan*np.ones(e)    # phase_shift\n",
    "                                   ]).T\n",
    "\n",
    "        return edge_index, edge_features\n",
    "\n",
    "    def get_trafo_features(net):\n",
    "        # TODO: Add charging susceptance - b (p.u.), transformer tap ratio - tau\n",
    "\n",
    "        # Similar to get_line_features.\n",
    "        edge_index = net.trafo.loc[:, ['hv_bus', 'lv_bus',\n",
    "                                       'lv_bus', 'hv_bus']].values\n",
    "        edge_index = edge_index.reshape(-1, 2).T\n",
    "\n",
    "        # Impedance calculated as shown in pandapower docs:\n",
    "        # https://pandapower.readthedocs.io/en/v2.2.1/elements/trafo.html#impedance-values\n",
    "        # where vk_percent is short-circuit voltage and vkr_percent is the real\n",
    "        # part of short-circuit voltage (%).\n",
    "        z_pu = (net.trafo['vk_percent'].values / 100)*(1000 / net.trafo['sn_mva'].values)\n",
    "        r_pu = (net.trafo['vkr_percent'].values / 100)*(1000 / net.trafo['sn_mva'].values)\n",
    "        x_pu = np.sqrt(np.square(z_pu) - np.square(r_pu))\n",
    "\n",
    "        # Add phase shift angle (deg) as additional feature.\n",
    "        phase_shift = net.trafo['vk_percent'].values\n",
    "        \n",
    "        # Repeat the features (to match edge_index) and create feature matrix.\n",
    "        e = edge_index.shape[1] # b/c coo matrix\n",
    "        edge_features = np.vstack([np.ones(e),              # trafo?\n",
    "                                   r_pu.repeat(2),          # r_pu\n",
    "                                   x_pu.repeat(2),          # x_pu\n",
    "                                   phase_shift.repeat(2)    # phase_shift\n",
    "                                   ]).T\n",
    "\n",
    "        return edge_index, edge_features\n",
    "    \n",
    "    A_line, E_line = get_line_features(net)\n",
    "    A_trafo, E_trafo = get_trafo_features(net)\n",
    "    \n",
    "    # Combine and return the line and trafo features.\n",
    "    A = np.hstack([A_line, A_trafo])\n",
    "    E = np.vstack([E_line, E_trafo])\n",
    "    return A, E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Grids using powerdata-gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1-LV-rural1--0-no_sw',\n",
       " '1-LV-rural2--0-no_sw',\n",
       " '1-LV-rural3--0-no_sw',\n",
       " '1-LV-semiurb4--0-no_sw',\n",
       " '1-LV-semiurb5--0-no_sw',\n",
       " '1-LV-urban6--0-no_sw',\n",
       " '1-MV-comm--0-no_sw',\n",
       " '1-MV-rural--0-no_sw',\n",
       " '1-MV-semiurb--0-no_sw',\n",
       " '1-MV-urban--0-no_sw']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All simbench codes for distribution grids\n",
    "SB_CODES = get_dist_grid_codes()\n",
    "SB_CODES = list(filter(lambda x: \"no_sw\" in x and \"-MVLV-\" not in x, SB_CODES))\n",
    "SB_CODES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output directory: outputs/2024-12-30_19:23:46\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample count = 55, Sampling issues = 0, Divergences = 0, Rejections = 40 : 100%|██████████| 15/15 [00:03<00:00,  4.26it/s]\n",
      "Sample count = 24, Sampling issues = 0, Divergences = 0, Rejections = 21 : 100%|██████████| 3/3 [00:01<00:00,  2.46it/s]\n",
      "Sample count = 4, Sampling issues = 0, Divergences = 0, Rejections = 2 : 100%|██████████| 2/2 [00:00<00:00,  5.42it/s]\n",
      "Sample count = 82, Sampling issues = 0, Divergences = 0, Rejections = 67 : 100%|██████████| 15/15 [00:05<00:00,  2.95it/s]\n",
      "Sample count = 12, Sampling issues = 0, Divergences = 0, Rejections = 9 : 100%|██████████| 3/3 [00:00<00:00,  3.01it/s]\n",
      "Sample count = 7, Sampling issues = 0, Divergences = 0, Rejections = 5 : 100%|██████████| 2/2 [00:00<00:00,  3.39it/s]\n",
      "Sample count = 57, Sampling issues = 0, Divergences = 0, Rejections = 42 : 100%|██████████| 15/15 [00:04<00:00,  3.45it/s]\n",
      "Sample count = 10, Sampling issues = 0, Divergences = 0, Rejections = 7 : 100%|██████████| 3/3 [00:00<00:00,  3.94it/s]\n",
      "Sample count = 4, Sampling issues = 0, Divergences = 0, Rejections = 2 : 100%|██████████| 2/2 [00:00<00:00,  4.59it/s]\n",
      "Sample count = 136, Sampling issues = 0, Divergences = 0, Rejections = 121 : 100%|██████████| 15/15 [00:06<00:00,  2.46it/s]\n",
      "Sample count = 52, Sampling issues = 0, Divergences = 0, Rejections = 49 : 100%|██████████| 3/3 [00:01<00:00,  1.62it/s]\n",
      "Sample count = 33, Sampling issues = 0, Divergences = 0, Rejections = 31 : 100%|██████████| 2/2 [00:01<00:00,  1.78it/s]\n",
      "Sample count = 92, Sampling issues = 0, Divergences = 0, Rejections = 77 : 100%|██████████| 15/15 [00:05<00:00,  2.88it/s]\n",
      "Sample count = 14, Sampling issues = 0, Divergences = 0, Rejections = 11 : 100%|██████████| 3/3 [00:00<00:00,  3.06it/s]\n",
      "Sample count = 4, Sampling issues = 0, Divergences = 0, Rejections = 2 : 100%|██████████| 2/2 [00:00<00:00,  4.47it/s]\n",
      "Sample count = 72, Sampling issues = 0, Divergences = 0, Rejections = 57 : 100%|██████████| 15/15 [00:04<00:00,  3.23it/s]\n",
      "Sample count = 18, Sampling issues = 0, Divergences = 0, Rejections = 15 : 100%|██████████| 3/3 [00:00<00:00,  3.07it/s]\n",
      "Sample count = 7, Sampling issues = 0, Divergences = 0, Rejections = 5 : 100%|██████████| 2/2 [00:00<00:00,  3.72it/s]\n",
      "Sample count = 44, Sampling issues = 0, Divergences = 0, Rejections = 29 : 100%|██████████| 15/15 [00:05<00:00,  2.74it/s]\n",
      "Sample count = 21, Sampling issues = 0, Divergences = 0, Rejections = 18 : 100%|██████████| 3/3 [00:01<00:00,  2.15it/s]\n",
      "Sample count = 7, Sampling issues = 0, Divergences = 0, Rejections = 5 : 100%|██████████| 2/2 [00:00<00:00,  2.38it/s]\n",
      "Sample count = 61, Sampling issues = 0, Divergences = 0, Rejections = 46 : 100%|██████████| 15/15 [00:04<00:00,  3.01it/s]\n",
      "Sample count = 13, Sampling issues = 0, Divergences = 0, Rejections = 10 : 100%|██████████| 3/3 [00:00<00:00,  3.10it/s]\n",
      "Sample count = 17, Sampling issues = 0, Divergences = 0, Rejections = 15 : 100%|██████████| 2/2 [00:00<00:00,  2.04it/s]\n",
      "Sample count = 61, Sampling issues = 0, Divergences = 0, Rejections = 46 : 100%|██████████| 15/15 [00:05<00:00,  2.98it/s]\n",
      "Sample count = 6, Sampling issues = 0, Divergences = 0, Rejections = 3 : 100%|██████████| 3/3 [00:00<00:00,  3.28it/s]\n",
      "Sample count = 6, Sampling issues = 0, Divergences = 0, Rejections = 4 : 100%|██████████| 2/2 [00:00<00:00,  3.37it/s]\n",
      "Sample count = 76, Sampling issues = 0, Divergences = 0, Rejections = 61 : 100%|██████████| 15/15 [00:04<00:00,  3.10it/s]\n",
      "Sample count = 7, Sampling issues = 0, Divergences = 0, Rejections = 4 : 100%|██████████| 3/3 [00:00<00:00,  3.92it/s]\n",
      "Sample count = 2, Sampling issues = 0, Divergences = 0, Rejections = 0 : 100%|██████████| 2/2 [00:00<00:00,  4.93it/s]\n"
     ]
    }
   ],
   "source": [
    "TEST_GENERATION = False\n",
    "TEST_SB_CODES = ['1-LV-rural1--0-no_sw']\n",
    "DATASET_SPLIT = [15,3,2] # [Train, val, test]\n",
    "\n",
    "# Setup input directory\n",
    "input_dir = 'inputs/'\n",
    "os.makedirs(input_dir, exist_ok=True)\n",
    "\n",
    "# Convert simbench codes to json files, if not already done.\n",
    "sb_codes = TEST_SB_CODES if TEST_GENERATION else SB_CODES\n",
    "filenames = []\n",
    "for code in sb_codes:\n",
    "    f = os.path.join(input_dir, f'{code}.json')\n",
    "    if not os.path.exists(f):\n",
    "        save_pandapower_grid_to_json(code, f)\n",
    "    filenames.append(f)\n",
    "\n",
    "# Load a base config file and change adjust parameters.\n",
    "cfg = OmegaConf.load('base_gen_config.yaml')\n",
    "cfg.n_train, cfg.n_val, cfg.n_test = DATASET_SPLIT\n",
    "cfg.seed = 12\n",
    "\n",
    "# Set up logger (for powerdata-gen)\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "# Create output directory for all data from this run, loop through ref grids, \n",
    "# generate new grids for each ref, save them to subdir of output dir.\n",
    "output_dir = create_output_dir()\n",
    "print(f'Output directory: {output_dir}\\n')\n",
    "generated_grid_base_dirs = []\n",
    "for code, f in list(zip(sb_codes, filenames)):\n",
    "    save_path = os.path.join(output_dir, code)\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    cfg.default_net_path = f\n",
    "    powerdata_gen.build_datasets(cfg.default_net_path, save_path, log, cfg.n_train, cfg.n_val, cfg.n_test, cfg.keep_reject,\n",
    "                   cfg.sampling, cfg.powerflow, cfg.filtering, cfg.seed)\n",
    "    generated_grid_base_dirs.append(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create datasets for GNN-based model development using the generated grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_splits = ['train', 'val', 'test']\n",
    "\n",
    "for split in dataset_splits:\n",
    "    # Gather all the grids for a particular dataset split\n",
    "    for dir in generated_grid_base_dirs:\n",
    "        generated_grid_dir = os.path.join(dir, split)\n",
    "        generated_grids = os.listdir(generated_grid_dir)\n",
    "        # list[outputs/<identifier>/<sb_code>/<train|test|val>/sample_<N>.json]\n",
    "        generated_grid_files = [os.path.join(generated_grid_dir, f) for f in generated_grids]\n",
    "\n",
    "        dataset_filename = os.path.join(generated_grid_dir,\n",
    "                                        f'dataset_{split}.pt')\n",
    "\n",
    "        if os.path.exists(dataset_filename):\n",
    "            continue\n",
    "        dataset = []\n",
    "\n",
    "        for f in generated_grid_files:\n",
    "            if f.split('.')[-1] != 'json':\n",
    "                # There could be non json files that exist, so skip them.\n",
    "                continue\n",
    "            net = pp.from_json(f)\n",
    "\n",
    "            X_i, Y_i = get_node_features(net)\n",
    "            A_i, E_i = get_edge_features(net)\n",
    "\n",
    "            dataset.append(\n",
    "                Data(x=torch.tensor(X_i),\n",
    "                    edge_index=torch.tensor(A_i, dtype=torch.int64),\n",
    "                    edge_attr=torch.tensor(E_i),\n",
    "                    y=torch.tensor(Y_i))\n",
    "            )\n",
    "        \n",
    "        print(\"Saving dataset\", dataset_filename, end=\"... \")\n",
    "        torch.save(dataset, dataset_filename)\n",
    "        print(\"completed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn-powerflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
